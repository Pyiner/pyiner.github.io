---
layout: default
title: Python爬虫教程——简单的抓取
---
本系列文章将从最基础的爬虫讲起，一点点的学习Python爬虫方面的知识。
假设你已经对Python的基础语法有所了解，如果还不了解Python的基础语法，那么请先学习下。

我们写爬虫 主要的目的就是要抓取网页上的内容，那么我们第一步就是要获取整个网页的源码，也就是HTML

那么在抓取网页之前呢 我们还需要安装我们需要的工具，这里我们最先用到的是 requests这个模块

从[https://github.com/kennethreitz/requests/zipball/master](https://github.com/kennethreitz/requests/zipball/master)这里下载 然后解压 进入cmd 在解压的目录下执行

	python setup.py install
首先导入需要的模块

	>>> import requests

现在，我们尝试打开一个页面。在这里我们打开GitHub的公共时间表

	>>> r = requests.get('https://github.com/timeline.json')
然后我们得到一个一个名为r的响应对象,我们可以从这个对象中获取所有我们想要的东西。
如果我们想得到请求的响应正文（HTML代码）的话，让我们再一次看GitHub的公共时间表这个例子：

	>>> r.text
	'[{"repository":{"open_issues":0,"url":"https://github.com/...

可以自行尝试别的各种网址

我们获取了整个网页的HTML 这还远远不够  我们要的是某一部分的内容 我们通过BeautifulSoup来获取

[http://www.crummy.com/software/BeautifulSoup/bs4/download/beautifulsoup4-4.1.3.tar.gz ](http://www.crummy.com/software/BeautifulSoup/bs4/download/beautifulsoup4-4.1.3.tar.gz)

我们从这里获取BeautifulSoup

使用下面的语句来安装

	python setup.py install
使用下来的语句来导入模块

	from bs4 import BeautifulSoup
我们来获取博客园http://www.cnblogs.com/的头条新闻名称

![](http://bcs.duapp.com/blog-pyiner/QQ%E6%88%AA%E5%9B%BE20130814164138.png?sign=MBO:528b10b38a1b368b5a572d8d459f541b:g29Jq0MxcAXZbWH85FO66EhqNlY%3D)

我们首先获取博客园的首页HTML

	>>> import requests
	>>> r = requests.get('http://www.cnblogs.com/')
	>>> r.text
我们可以看到头条在HTML代码中的情况

我们可以看到所有内容在id为'headline_block'这个标签里 所有头条的新闻链接都是a标签 所以我们的代码如下
	
	>>> from bs4 import BeautifulSoup
	>>> import requests
	>>> r = requests.get('http://www.cnblogs.com/')
	>>> soup = BeautifulSoup(r.text)
	>>> n=soup.find(id='headline_block').findAll('a')
	>>> n
	[<a href="http://www.cnblogs.com/geniusvczh/archive/2013/04/28/3049774.html" id="editor_pick_lnk" target="_blank">【编辑推荐】如何设计一门语言（二）——什么是坑(b)<span id="editor_pick_count"></span></a>, <a class="right_more" href="/aggsite/headline" title="查看更多编辑推荐">»</a>, <a href="http://www.cnblogs.com/yexiaochai/archive/2013/05/01/3051632.html" target="_blank" title="阅读1110, 评论11, 推荐4">[最多推荐]【实战HTML5与CSS3 第二篇】绚丽的快速导航！(11/1110)</a>, <a class="right_more" href="http://home.cnblogs.com/blog/Headline.aspx" title="查看更多推荐头条">»</a>, <a href="http://www.cnblogs.com/yexiaochai/archive/2013/05/01/3052782.html" target="_blank" title="阅读879, 评论10, 推荐3">[最多评论]【实战HTML5与CSS3 第三篇】我第一个HTML5网页诞生了(提供源码)(10/879)</a>, <a href="http://news.cnblogs.com/n/176771/" target="_blank" title="阅读251, 评论2, 推荐4">[新闻头条]阮一峰：字符串匹配的KMP算法(2/251)</a>, <a class="right_more" href="http://news.cnblogs.com/" title="查看更多新闻">»</a>, <a href="http://news.cnblogs.com/n/176695/" target="_blank" title="阅读2007, 评论9, 推荐1">[推荐新闻]“阿里浪”终于尘埃落定，5.86亿美金占新浪微博18%的股份(9/2007)</a>, <a class="right_more" href="http://news.cnblogs.com/n/recommend" title="查看更多推荐新闻">»</a>]
	>>> for i in n:
		print i.text
	
	【编辑推荐】如何设计一门语言（二）——什么是坑(b)
	»
	[最多推荐]【实战HTML5与CSS3 第二篇】绚丽的快速导航！(11/1110)
	»
	[最多评论]【实战HTML5与CSS3 第三篇】我第一个HTML5网页诞生了(提供源码)(10/879)
	[新闻头条]阮一峰：字符串匹配的KMP算法(2/251)
	»
	[推荐新闻]“阿里浪”终于尘埃落定，5.86亿美金占新浪微博18%的股份(9/2007)
	»
	>>> 
好啦 我们的第一篇文章就介绍到这里